{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikel/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import cv2\n",
    "from skimage import feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from natsort import natsorted\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except:\n",
    "    print('XGBoost not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(vehicle_loc='./vehicles/', non_loc='./non-vehicles/', train_pct=0.75):\n",
    "    veh_files = glob.glob(vehicle_loc + '**/*.png', recursive=True)\n",
    "    non_files = glob.glob(non_loc + '**/*.png', recursive=True)\n",
    "    \n",
    "    print('[DataLoader] Found {} vehicle and {} non-vehicle images. Loading...'.format(len(veh_files), len(non_files)))\n",
    "\n",
    "    x_train = []\n",
    "    x_valid = []\n",
    "    y_train = []\n",
    "    y_valid = []\n",
    "    \n",
    "    # Do train/validation split _properly_\n",
    "    for target, dataset in enumerate([non_files, veh_files]):\n",
    "        folders = list(set(['/'.join(f.split('/')[:-1]) for f in dataset])) # Get unique folders\n",
    "        print(folders)\n",
    "        for folder in folders:\n",
    "            # Sort each folder by time series\n",
    "            folder_files = natsorted([f for f in dataset if folder in f])\n",
    "            # Split into train and validation\n",
    "            folder_files_train = folder_files[:int(len(folder_files) * train_pct)]\n",
    "            folder_files_valid = folder_files[int(len(folder_files) * train_pct):]\n",
    "            \n",
    "            print('Loading ({}) {} - {} train {} valid'.format(target, folder, len(folder_files_train), len(folder_files_valid)))\n",
    "            \n",
    "            folder_imgs_train = [cv2.imread(f) for f in folder_files_train]\n",
    "            folder_imgs_valid = [cv2.imread(f) for f in folder_files_valid]\n",
    "            \n",
    "            x_train.extend(folder_imgs_train)\n",
    "            x_valid.extend(folder_imgs_valid)\n",
    "            y_train.extend([target for _ in folder_files_train])\n",
    "            y_valid.extend([target for _ in folder_files_valid])\n",
    "    \n",
    "    return np.array(x_train), np.array(x_valid), np.array(y_train), np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    return features\n",
    "\n",
    "# Extract features from an image\n",
    "def process_image(img):\n",
    "    if img.shape != (64, 64, 3):\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    hog = feature.hog(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), transform_sqrt=True, orientations=8, cells_per_block=(2, 2))\n",
    "    hist = color_hist(img)\n",
    "    hist2 = color_hist(hls_img)\n",
    "    spatial = bin_spatial(img, size=(16, 16))\n",
    "    spatial2 = bin_spatial(hls_img, size=(16, 16))\n",
    "    return np.concatenate([hog, hist, hist2, spatial, spatial2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take in an image, and split into many sliding windows\n",
    "def sliding_window_sampler(img, offset=32, block_size=64):\n",
    "    data_img = []\n",
    "    shape = img.shape\n",
    "\n",
    "    for xo in range(((shape[0] - block_size) // offset)+1):\n",
    "        for yo in range(((shape[1] - block_size) // offset)+1):  \n",
    "            mini_img = img[xo*offset:xo*offset+block_size, yo*offset:yo*offset+block_size, :]\n",
    "            data_img.append(mini_img)\n",
    "    return np.array(data_img)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(12) # Open 12 multiprocessing threads\n",
    "\n",
    "# Search over many different search spaces simulatenously\n",
    "def sliding_window_dual(input_img, clf, gbm, search_spaces, std=None):\n",
    "    heatmap = np.zeros(input_img.shape[:2])\n",
    "    heatmap2 = np.zeros(input_img.shape[:2])\n",
    "    \n",
    "    # Repeat in each search space\n",
    "    for top, bottom, left, right, block_size, offset in search_spaces:\n",
    "        img = input_img[top:bottom, left:right]\n",
    "        shape = img.shape\n",
    "        #print(img.shape)\n",
    "        \n",
    "        # Get windows\n",
    "        data_img = sliding_window_sampler(img, offset=offset, block_size=block_size)\n",
    "        \n",
    "        # Multithreaded feature generation\n",
    "        x_img = np.array(pool.map(process_image, data_img))\n",
    "\n",
    "        # Predict with both models\n",
    "        p2 = gbm.predict(xgb.DMatrix(x_img))\n",
    "        p = clf.predict(std.transform(x_img))\n",
    "\n",
    "        # Loop over the blocks, adding to the heatmap\n",
    "        i = 0\n",
    "        for xo in range(((shape[0] - block_size) // offset)+1):\n",
    "            for yo in range(((shape[1] - block_size) // offset)+1):    \n",
    "                heatmap[(xo*offset)+top:(xo*offset+block_size)+top, (yo*offset)+left:(yo*offset+block_size)+left] += p[i]\n",
    "                i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for xo in range(((shape[0] - block_size) // offset)+1):\n",
    "            for yo in range(((shape[1] - block_size) // offset)+1):    \n",
    "                heatmap2[(xo*offset)+top:(xo*offset+block_size)+top, (yo*offset)+left:(yo*offset+block_size)+left] += p2[i]\n",
    "                i += 1\n",
    "        \n",
    "    # Return the two heatmaps\n",
    "    return heatmap, heatmap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train an XGBoost model\n",
    "def run_xgb(x_train, y_train, x_valid, y_valid):\n",
    "    # Define parameters for XGBoost\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = ['auc', 'error']\n",
    "    params['eta'] = 0.1\n",
    "    params['colsample_bylevel'] = 0.1\n",
    "    params['subsample'] = 0.8\n",
    "    params['max_depth'] = 20\n",
    "    \n",
    "    # Convert data to C++ DataMatrix format\n",
    "    d_train = xgb.DMatrix(x_train, y_train)\n",
    "    d_valid = xgb.DMatrix(x_valid, y_valid)\n",
    "    \n",
    "    # Define datasets\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    \n",
    "    # Train XGBoost with early stopping\n",
    "    clf = xgb.train(params, d_train, 1000, watchlist, verbose_eval=10, early_stopping_rounds=100)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train a LinearSVC with standard-scaling\n",
    "def run_sklearn(x_train, y_train, x_valid, y_valid):\n",
    "    \n",
    "    std = StandardScaler()\n",
    "    x_train = std.fit_transform(x_train)\n",
    "    x_valid = std.transform(x_valid)\n",
    "    \n",
    "    clf = LinearSVC() #SVC(kernel='linear')\n",
    "    clf.fit(x_train, y_train)\n",
    "    p_train = clf.predict(x_train)\n",
    "    p_valid = clf.predict(x_valid)\n",
    "    \n",
    "    # Training and validation accuracy\n",
    "    print((p_train == y_train).mean(), (p_valid == y_valid).mean())\n",
    "    return clf, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataLoader] Found 8792 vehicle and 8968 non-vehicle images. Loading...\n",
      "['./non-vehicles/non-vehicles/GTI', './non-vehicles/non-vehicles/Extras']\n",
      "Loading (0) ./non-vehicles/non-vehicles/GTI - 2925 train 975 valid\n",
      "Loading (0) ./non-vehicles/non-vehicles/Extras - 3801 train 1267 valid\n",
      "['./vehicles/vehicles/KITTI_extracted', './vehicles/vehicles/GTI_Far', './vehicles/vehicles/GTI_MiddleClose', './vehicles/vehicles/GTI_Right', './vehicles/vehicles/GTI_Left']\n",
      "Loading (1) ./vehicles/vehicles/KITTI_extracted - 4474 train 1492 valid\n",
      "Loading (1) ./vehicles/vehicles/GTI_Far - 625 train 209 valid\n",
      "Loading (1) ./vehicles/vehicles/GTI_MiddleClose - 314 train 105 valid\n",
      "Loading (1) ./vehicles/vehicles/GTI_Right - 498 train 166 valid\n",
      "Loading (1) ./vehicles/vehicles/GTI_Left - 681 train 228 valid\n",
      "1.0 0.977037370554\n",
      "[0]\ttrain-auc:0.997609\ttrain-error:0.013215\tvalid-auc:0.980029\tvalid-error:0.053579\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n",
      "[10]\ttrain-auc:0.999997\ttrain-error:0.000451\tvalid-auc:0.995938\tvalid-error:0.037145\n",
      "[20]\ttrain-auc:1\ttrain-error:0.00015\tvalid-auc:0.996338\tvalid-error:0.034219\n",
      "[30]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.996455\tvalid-error:0.034669\n",
      "[40]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.997195\tvalid-error:0.033994\n",
      "[50]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.997617\tvalid-error:0.032643\n",
      "[60]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.997816\tvalid-error:0.031968\n",
      "[70]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.99811\tvalid-error:0.031968\n",
      "[80]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998337\tvalid-error:0.030842\n",
      "[90]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.99849\tvalid-error:0.029716\n",
      "[100]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998654\tvalid-error:0.027915\n",
      "[110]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998744\tvalid-error:0.026565\n",
      "[120]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998833\tvalid-error:0.025889\n",
      "[130]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998887\tvalid-error:0.025664\n",
      "[140]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.998941\tvalid-error:0.025214\n",
      "[150]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999008\tvalid-error:0.024764\n",
      "[160]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999052\tvalid-error:0.023638\n",
      "[170]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999071\tvalid-error:0.022963\n",
      "[180]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999085\tvalid-error:0.022512\n",
      "[190]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999117\tvalid-error:0.021837\n",
      "[200]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999132\tvalid-error:0.021387\n",
      "[210]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999159\tvalid-error:0.021162\n",
      "[220]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999177\tvalid-error:0.020937\n",
      "[230]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.99919\tvalid-error:0.020261\n",
      "[240]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999202\tvalid-error:0.020486\n",
      "[250]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999203\tvalid-error:0.020486\n",
      "[260]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999225\tvalid-error:0.020261\n",
      "[270]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999226\tvalid-error:0.020261\n",
      "[280]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999222\tvalid-error:0.020261\n",
      "[290]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999231\tvalid-error:0.020036\n",
      "[300]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999231\tvalid-error:0.019811\n",
      "[310]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999235\tvalid-error:0.019361\n",
      "[320]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999238\tvalid-error:0.019586\n",
      "[330]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999244\tvalid-error:0.01891\n",
      "[340]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999257\tvalid-error:0.018685\n",
      "[350]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999259\tvalid-error:0.01891\n",
      "[360]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999258\tvalid-error:0.01846\n",
      "[370]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999256\tvalid-error:0.01846\n",
      "[380]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999259\tvalid-error:0.018235\n",
      "[390]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999264\tvalid-error:0.018235\n",
      "[400]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999254\tvalid-error:0.018235\n",
      "[410]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999261\tvalid-error:0.018235\n",
      "[420]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.99926\tvalid-error:0.018235\n",
      "[430]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999266\tvalid-error:0.018235\n",
      "[440]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999259\tvalid-error:0.018235\n",
      "[450]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999254\tvalid-error:0.018235\n",
      "[460]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999258\tvalid-error:0.018235\n",
      "Stopping. Best iteration:\n",
      "[369]\ttrain-auc:1\ttrain-error:0\tvalid-auc:0.999255\tvalid-error:0.018235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "x_train, x_valid, y_train, y_valid = data_loader()\n",
    "# Create features\n",
    "x2_train = np.array([process_image(img) for img in x_train])\n",
    "x2_valid = np.array([process_image(img) for img in x_valid])\n",
    "# Train linear SVM\n",
    "clf, std = run_sklearn(x2_train, y_train, x2_valid, y_valid)\n",
    "# Train XGBoost\n",
    "gbm = run_xgb(x2_train, y_train, x2_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "# This function takes in a raw image and car mask, and finds all connected pixels to form bounding boxes\n",
    "# around the cars\n",
    "def binary_mask_to_boxes(img, heatmap):\n",
    "    img = img.copy()\n",
    "    clusters = measure.label(heatmap)\n",
    "    for label in np.unique(clusters)[1:]:\n",
    "        where = np.where(clusters == label)\n",
    "        xmin, xmax, ymin, ymax = where[1].min(), where[1].max(), where[0].min(), where[0].max()\n",
    "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 6)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_heatmap = None\n",
    "last_heatmap2 = None\n",
    "alpha = 0.2\n",
    "\n",
    "def run_img(img):\n",
    "    global last_heatmap, last_heatmap2\n",
    "    rgb = img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # These are the defined sliding window parameters. The format is as follows:\n",
    "    # (ymin, ymax, xmin, xmax, window_size, stride)\n",
    "    search_spaces = [\n",
    "    (380, 500, 0, 1280, 64, 16),\n",
    "    (380, 600, 0, 1280, 96, 32),\n",
    "    (400, 700, 0, 1280, 128, 32),\n",
    "    (400, 700, 0, 1280, 256, 64)\n",
    "    ]\n",
    "    \n",
    "    # Do a sliding window search to get heatmaps\n",
    "    heatmap, heatmap2 = sliding_window_dual(img, clf, gbm, search_spaces, std)\n",
    "    \n",
    "    # Do a weighted mean with the last frame\n",
    "    if last_heatmap is not None:\n",
    "        heatmap = (heatmap * alpha) + (last_heatmap * (1 - alpha))\n",
    "        heatmap2 = (heatmap2 * alpha) + (last_heatmap2 * (1 - alpha))\n",
    "    last_heatmap = heatmap\n",
    "    last_heatmap2 = heatmap2\n",
    "    \n",
    "    # Create a mask from the intersection of the two heatmaps\n",
    "    mask = (heatmap > 3) & (heatmap2 > 0.1)\n",
    "    \n",
    "    # Apply bounding boxes to images\n",
    "    output = binary_mask_to_boxes(rgb, mask)\n",
    "    plt.imshow(output)\n",
    "    plt.show()\n",
    "    return output\n",
    "    \n",
    "    \n",
    "from moviepy.editor import VideoFileClip\n",
    "white_output = 'out16.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(run_img) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
